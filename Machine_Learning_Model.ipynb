{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import session\n",
    "from sqlalchemy import create_engine, func\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "#Connect to sqlite\n",
    "connection = sqlite3.connect(\":memory:\")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#Read in sql file\n",
    "sql_file = open(\"living_in_nashville.sql\", encoding=\"utf8\")\n",
    "sql_as_string = sql_file.read()\n",
    "cursor.executescript(sql_as_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create housing DataFrame\n",
    "housing_list = []\n",
    "for row in cursor.execute(\"SELECT * FROM Nashville_Housing_Data\"):\n",
    "    housing_list.append(row)\n",
    "\n",
    "#housing_df\n",
    "housing_df = pd.DataFrame(housing_list)\n",
    "housing_df.columns = ['Unnamed:0',\"ParcelID\",\"LandUse\",\"PropertyAddress\",\"Suite/Condo#\",\"PropertyCity\",\"ZipCode\",\"SaleDate\",\"SalePrice\",\"LegalReference\",\"SoldAsVacant\",\"MultipleParcelsInvolvedinSale\",\"OwnerName\",\"Address\",\"City\",\"State\",\"Acreage\",\"TaxDistrict\",\"Neighborhood\",\"image\",\"LandValue\",\"BuildingValue\",\"TotalValue\",\"FinishedArea\",\"FoundationType\",\"YearBuilt\",\"ExteriorWall\",\"Grade\",\"Bedrooms\",\"FullBath\",\"HalfBath\"]\n",
    "housing_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Parks DataFrame\n",
    "parks_list = []\n",
    "for row in cursor.execute(\"SELECT * FROM Park_Locations\"):\n",
    "    parks_list.append(row)\n",
    "\n",
    "parks_df = pd.DataFrame(parks_list)\n",
    "parks_df.columns= [\"ParkName\",\"ZipCodes\",\"Acres\",\"CommunityCenter\",\"NatureCenter\",\"Playground\",\"ADAAccessible\",\"RestroomsAvailable\",\"DogPark\",\"BaseballFields\",\"BasketballCourts\",\"SoccerFields\",\"Football&Multi-purposeFields\",\"TennisCourts\",\"DiscGolf\",\"SwimmingPool\",\"GolfCourse\",\"Walk&JogPaths\",\"HistoricFeatures\",\"MappedLocation\",\"Lat\",\"Lng\"]\n",
    "parks_df=parks_df.replace({'Yes':True,'No':False})\n",
    "parks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list for of whether Walk and Jog is True\n",
    "walk_list_per_zip = parks_df.groupby('ZipCodes')['Walk&JogPaths'].apply(list)\n",
    "walk_per_zip = []\n",
    "for code in walk_list_per_zip:\n",
    "    if True in code:\n",
    "        walk_per_zip.append(True)\n",
    "    else: walk_per_zip.append(False)\n",
    "walk_per_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list for baseball\n",
    "baseball_per_zip = parks_df.groupby('ZipCodes')['BaseballFields'].apply(list)\n",
    "baseball_list = []\n",
    "for code in baseball_per_zip:\n",
    "    if True in code:\n",
    "        baseball_list.append(True)\n",
    "    else: baseball_list.append(False)\n",
    "#Create list for basketball\n",
    "basketball_per_zip = parks_df.groupby('ZipCodes')['BasketballCourts'].apply(list)\n",
    "basketball_list = []\n",
    "for code in basketball_per_zip:\n",
    "    if True in code:\n",
    "        basketball_list.append(True)\n",
    "    else: basketball_list.append(False)\n",
    "#Create list for Soccer\n",
    "soccer_per_zip = parks_df.groupby('ZipCodes')['SoccerFields'].apply(list)\n",
    "soccer_list = []\n",
    "for code in soccer_per_zip:\n",
    "    if True in code:\n",
    "        soccer_list.append(True)\n",
    "    else: soccer_list.append(False)\n",
    "#Create list for Football\n",
    "football_per_zip = parks_df.groupby('ZipCodes')['Football&Multi-purposeFields'].apply(list)\n",
    "football_list = []\n",
    "for code in football_per_zip:\n",
    "    if True in code:\n",
    "        football_list.append(True)\n",
    "    else: football_list.append(False)\n",
    "#Create list for Tennis\n",
    "tennis_per_zip = parks_df.groupby('ZipCodes')['TennisCourts'].apply(list)\n",
    "tennis_list = []\n",
    "for code in tennis_per_zip:\n",
    "    if True in code:\n",
    "        tennis_list.append(True)\n",
    "    else: tennis_list.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip together individual sport lists\n",
    "sports_tuples = list(zip(baseball_list,basketball_list,soccer_list,football_list,tennis_list))\n",
    "sports_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list for whether any of the sports lists contain true in each zip\n",
    "sports_list = []\n",
    "for row in sports_tuples:\n",
    "    if True in row:\n",
    "        sports_list.append(True)\n",
    "    else: sports_list.append(False)\n",
    "\n",
    "sports_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by zip code and find if there is a yes in ADA column\n",
    "\n",
    "ada_list_per_zip = parks_df.groupby('ZipCodes')['ADAAccessible'].apply(list)\n",
    "ada_per_zip = []\n",
    "for code in ada_list_per_zip:\n",
    "    if True in code:\n",
    "        ada_per_zip.append(True)\n",
    "    else: ada_per_zip.append(False)\n",
    "ada_per_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parks per zip code variable\n",
    "parks_per_zip = parks_df.groupby('ZipCodes').size()\n",
    "parks_per_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable for total acres of parks per zip code\n",
    "acres_per_zip = parks_df.groupby('ZipCodes').sum()['Acres']\n",
    "acres_per_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new DataFrame with created variables\n",
    "parks_new_tuples = list(zip(parks_per_zip, acres_per_zip, ada_per_zip, sports_list, walk_per_zip))\n",
    "parks_new_df = pd.DataFrame(parks_new_tuples, columns=[\"Parks Per Zip\", \"Acres of Parks Per Zip\", \"ADA Park in Zip\", \"Sports Fields in Zip\", \"Walk Path in Zip\"], index=parks_per_zip.index)\n",
    "parks_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge new parks df with housing df\n",
    "new_housing_df = housing_df.merge(parks_new_df, left_on=\"ZipCode\", right_on=\"ZipCodes\")\n",
    "new_housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_housing_df = new_housing_df.drop(columns=[\"ParcelID\", \"LandUse\",\"PropertyAddress\",\"Suite/Condo#\",\"Unnamed:0\",\"PropertyCity\",\"SaleDate\",\"LegalReference\",\"ExteriorWall\",\"Grade\",\"SoldAsVacant\",\"MultipleParcelsInvolvedinSale\",\"OwnerName\",\"Address\",\"City\",\"State\", \"FoundationType\",\"TaxDistrict\",\"image\",\"Neighborhood\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_housing_df = new_housing_df.dropna()\n",
    "new_housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Export the Dataframe as a new CSV file without the index.\n",
    "new_housing_df.to_csv('./Cleaned_Data/new_housing_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from path import Path\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(new_housing_df.YearBuilt, new_housing_df.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(new_housing_df.FinishedArea, new_housing_df.SalePrice)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(new_housing_df.Acreage, new_housing_df.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(new_housing_df.Bedrooms, new_housing_df.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = new_housing_df['SalePrice'].values\n",
    "X = new_housing_df.drop('SalePrice',1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a linear regression model \n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting our model with all our features in X\n",
    "model.fit(X, y)\n",
    "\n",
    "score = model.score(X, y)\n",
    "print(f\"R2 Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Schools DataFrame\n",
    "schools_list = []\n",
    "for row in cursor.execute(\"SELECT * FROM MNPS_Enrollment_Data\"):\n",
    "    schools_list.append(row)\n",
    "\n",
    "\n",
    "schools_df = pd.DataFrame(schools_list)\n",
    "schools_df.columns = [\"SchoolLevel\",\"SchoolName\",\"ZipCode\",\"Rank\",\"Greatschoolsrating\",\"TotalEnrollment\",\"AmericanIndianorAlaskaNative\",\"Asian\",\"BlackorAfricanAmerican\",\"Hispanic/Latino\",\"NativeHawaiianorOtherPacificIslander\",\"White\",\"StudentswithDisabilities\"]\n",
    "schools_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Schools DataFrame\n",
    "restaurant_list = []\n",
    "for row in cursor.execute(\"SELECT * FROM Nashville_Restaurants\"):\n",
    "    restaurant_list.append(row)\n",
    "\n",
    "\n",
    "restaurant_df = pd.DataFrame(restaurant_list)\n",
    "restaurant_df.columns = [\"Restaurant Name\",\"Neighborhood\",\"Address\",\"ZIP Code\",\"Description\"]\n",
    "restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_per_zip = restaurant_df.groupby('ZIP Code').size()\n",
    "restaurant_per_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_restaurants_df = pd.DataFrame(restaurant_per_zip, columns=[\"RestaurantsPerZip\"], index=restaurant_per_zip.index)\n",
    "new_restaurants_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86969af4118fd2beaee010b14a97d3c8fe7dc31ff55f1528eea7eaecb45368d6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
